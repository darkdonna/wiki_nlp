{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad8bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import collocations\n",
    "from nltk import pos_tag as pos\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.corpora import MmCorpus\n",
    "from gensim.models import LdaModel, LdaMulticore, CoherenceModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091735d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 488\n"
     ]
    }
   ],
   "source": [
    "# Import all CSV files from all Wiki articles and save them to one list\n",
    "files = glob.glob(\"articles/*.csv\")\n",
    "\n",
    "all_articles = []\n",
    "\n",
    "for file in files:\n",
    "    read_handle = open(file, \"r\")\n",
    "    text = list(csv.reader(read_handle, delimiter=\",\"))        \n",
    "    for article in text[1:]:\n",
    "        all_articles.append(article[1])     \n",
    "\n",
    "# How many articles has been read\n",
    "print('Number of articles:', len(all_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8254a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens groups: 488 \n",
      "\n",
      "-No-   --Tokens--\n",
      "  1       324\n",
      "  2       737\n",
      "  3       164\n",
      "  4       238\n",
      "  5       276\n",
      "  6       162\n",
      "  7       547\n",
      "  8       172\n",
      "  9       546\n",
      " 10      1168\n",
      " 11       324\n",
      " 12       396\n",
      " 13       386\n",
      " 14        95\n",
      " 15       298\n"
     ]
    }
   ],
   "source": [
    "all_tokens = []\n",
    "\n",
    "# import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "for article in all_articles:\n",
    "    # Removing section headers and new line breaks\n",
    "    text = re.sub(\"==.*==\",'', article)\n",
    "    text = re.sub(\"\\n\",'', text)\n",
    "    \n",
    "    # Convert a document into a list of tokens \n",
    "    # This lowercases, tokenizes, removes numerical values\n",
    "    tokens = simple_preprocess(text)\n",
    "    \n",
    "    doc_out = []\n",
    "    for word in tokens:    \n",
    "        if word not in stop_words:  # to remove stopwords\n",
    "            Lemmatized_Word = wnl.lemmatize(word)  # lemmatize\n",
    "            doc_out.append(Lemmatized_Word)\n",
    "    \n",
    "    all_tokens.append(doc_out)\n",
    "\n",
    "# Print out infromation about articles and number of tokens for top 15\n",
    "print('Tokens groups:', len(all_tokens),'\\n')\n",
    "print(\"{0:7}{1:10}\".format(\"-No-\",\"--Tokens--\"))\n",
    "for x, tokens in enumerate(all_tokens[:15]):\n",
    "    print(\"{0:3}{1:10}\".format(x + 1, len(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfbb6182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary length: 2299\n",
      "Top 20 tokens by frequency\n",
      "\n",
      "1. woman - 1486\n",
      "2. company - 1318\n",
      "3. president - 1271\n",
      "4. new - 1225\n",
      "5. business - 1113\n",
      "6. board - 1048\n",
      "7. school - 1040\n",
      "8. year - 997\n",
      "9. ceo - 979\n",
      "10. first - 964\n",
      "11. also - 942\n",
      "12. executive - 778\n",
      "13. state - 775\n",
      "14. director - 747\n",
      "15. one - 747\n",
      "16. award - 736\n",
      "17. york - 683\n",
      "18. time - 673\n",
      "19. served - 651\n",
      "20. national - 619\n",
      "\n",
      "Corpus length: 488\n"
     ]
    }
   ],
   "source": [
    "# create dictionary - a map of unique tokens\n",
    "dictionary = Dictionary(all_tokens)\n",
    "dictionary.filter_extremes(no_below = 10, no_above = 0.8)\n",
    "print('Dictionary length:', len(dictionary.keys()))\n",
    "\n",
    "# 100 tokens by frequency for cleaned up dictionary\n",
    "new_t_most_freq = dictionary.most_common(100)\n",
    "print('Top 20 tokens by frequency\\n')\n",
    "\n",
    "num = 1\n",
    "for t, f in new_t_most_freq[:20]:\n",
    "    print(str(num) + '.', t, '-', f)\n",
    "    num = num + 1\n",
    "\n",
    "\n",
    "# Create a MmCorpus: corpus\n",
    "corpus = [dictionary.doc2bow(token) for token in all_tokens]\n",
    "print('\\nCorpus length:', len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b17384",
   "metadata": {},
   "source": [
    "## Bigrams & Trigrams\n",
    "https://nicharuc.github.io/topic_modeling/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1cda4d",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "392b759d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bigrams: 277\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>pmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(hong, kong)</td>\n",
       "      <td>12.838263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(simon, schuster)</td>\n",
       "      <td>12.671039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(planned, parenthood)</td>\n",
       "      <td>12.548756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(cum, laude)</td>\n",
       "      <td>12.101297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(magna, cum)</td>\n",
       "      <td>12.101297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(leon, guerrero)</td>\n",
       "      <td>11.730871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(silicon, valley)</td>\n",
       "      <td>11.568174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(covid, pandemic)</td>\n",
       "      <td>11.441557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(joe, biden)</td>\n",
       "      <td>11.401351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(chamber, commerce)</td>\n",
       "      <td>11.330116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(rhode, island)</td>\n",
       "      <td>11.307748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(task, force)</td>\n",
       "      <td>10.982409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(hillary, clinton)</td>\n",
       "      <td>10.771149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(wall, street)</td>\n",
       "      <td>10.726723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(real, estate)</td>\n",
       "      <td>10.575228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(st, louis)</td>\n",
       "      <td>10.558569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(barack, obama)</td>\n",
       "      <td>10.527061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(los, angeles)</td>\n",
       "      <td>10.495118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(hall, fame)</td>\n",
       "      <td>10.465061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(honorary, doctorate)</td>\n",
       "      <td>10.461008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(air, force)</td>\n",
       "      <td>10.297795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(san, francisco)</td>\n",
       "      <td>10.255956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(donald, trump)</td>\n",
       "      <td>10.226828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(middle, east)</td>\n",
       "      <td>10.225008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(north, carolina)</td>\n",
       "      <td>10.200509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bigram        pmi\n",
       "0            (hong, kong)  12.838263\n",
       "1       (simon, schuster)  12.671039\n",
       "2   (planned, parenthood)  12.548756\n",
       "3            (cum, laude)  12.101297\n",
       "4            (magna, cum)  12.101297\n",
       "5        (leon, guerrero)  11.730871\n",
       "6       (silicon, valley)  11.568174\n",
       "7       (covid, pandemic)  11.441557\n",
       "8            (joe, biden)  11.401351\n",
       "9     (chamber, commerce)  11.330116\n",
       "10        (rhode, island)  11.307748\n",
       "11          (task, force)  10.982409\n",
       "12     (hillary, clinton)  10.771149\n",
       "13         (wall, street)  10.726723\n",
       "14         (real, estate)  10.575228\n",
       "15            (st, louis)  10.558569\n",
       "16        (barack, obama)  10.527061\n",
       "17         (los, angeles)  10.495118\n",
       "18           (hall, fame)  10.465061\n",
       "19  (honorary, doctorate)  10.461008\n",
       "20           (air, force)  10.297795\n",
       "21       (san, francisco)  10.255956\n",
       "22        (donald, trump)  10.226828\n",
       "23         (middle, east)  10.225008\n",
       "24      (north, carolina)  10.200509"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "\n",
    "finder = collocations.BigramCollocationFinder.from_documents(all_tokens)\n",
    "\n",
    "# Filter only those that occur at least N times\n",
    "finder.apply_freq_filter(20)\n",
    "bigram_scores = finder.score_ngrams(bigram_measures.pmi)\n",
    "\n",
    "# Create a dataframe with bigram PMI scores -  Pointwise Mutual Information\n",
    "bigram_pmi = pd.DataFrame(bigram_scores)\n",
    "bigram_pmi.columns = ['bigram', 'pmi']\n",
    "bigram_pmi.sort_values(by='pmi', axis = 0, ascending = False, inplace = True)\n",
    "print('Number of bigrams:',len(bigram_pmi.index))\n",
    "bigram_pmi.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5993a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for bigrams with only noun-type structures\n",
    "def bigram_filter(bigram):\n",
    "    tag = pos(bigram)\n",
    "    if tag[0][1] not in ['JJ', 'NN'] and tag[1][1] not in ['NN']:\n",
    "        return False\n",
    "    if bigram[0] in stop_words or bigram[1] in stop_words:\n",
    "        return False\n",
    "    if 'n' in bigram or 't' in bigram:\n",
    "        return False\n",
    "    if 'PRON' in bigram:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41370e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered bigrams: 180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>pmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(hong, kong)</td>\n",
       "      <td>12.838263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(simon, schuster)</td>\n",
       "      <td>12.671039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(planned, parenthood)</td>\n",
       "      <td>12.548756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(magna, cum)</td>\n",
       "      <td>12.101297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(leon, guerrero)</td>\n",
       "      <td>11.730871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  bigram        pmi\n",
       "0           (hong, kong)  12.838263\n",
       "1      (simon, schuster)  12.671039\n",
       "2  (planned, parenthood)  12.548756\n",
       "4           (magna, cum)  12.101297\n",
       "5       (leon, guerrero)  11.730871"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_bigram = bigram_pmi[bigram_pmi.apply(lambda bigram:\\\n",
    "                                              bigram_filter(bigram['bigram'])\\\n",
    "                                              and bigram.pmi > 5, axis = 1)][:500]\n",
    "print('Number of filtered bigrams:',len(filtered_bigram.index))\n",
    "filtered_bigram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c537e259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hewlett packard',\n",
       " 'alma mater',\n",
       " 'desmond hellmann',\n",
       " 'hong kong',\n",
       " 'ben ishay',\n",
       " 'simon schuster',\n",
       " 'von tobel',\n",
       " 'planned parenthood',\n",
       " 'phi beta',\n",
       " 'douglas elliman']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining bigrams\n",
    "bigrams = [' '.join(x) for x in filtered_bigram.bigram.values if len(x[0]) > 2 or len(x[1]) > 2]\n",
    "bigrams[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335fb2e3",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0316c965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trigrams: 140\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>pmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(buena, salud, guide)</td>\n",
       "      <td>25.723594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(phi, beta, kappa)</td>\n",
       "      <td>25.454133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(magna, cum, laude)</td>\n",
       "      <td>24.202595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(robert, wood, johnson)</td>\n",
       "      <td>21.496690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(graduated, magna, cum)</td>\n",
       "      <td>21.043672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   trigram        pmi\n",
       "0    (buena, salud, guide)  25.723594\n",
       "1       (phi, beta, kappa)  25.454133\n",
       "2      (magna, cum, laude)  24.202595\n",
       "3  (robert, wood, johnson)  21.496690\n",
       "4  (graduated, magna, cum)  21.043672"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_measures = collocations.TrigramAssocMeasures()\n",
    "finder = collocations.TrigramCollocationFinder.from_documents(all_tokens)\n",
    "# Filter only those that occur at least N times\n",
    "finder.apply_freq_filter(10)\n",
    "trigram_scores = finder.score_ngrams(trigram_measures.pmi)\n",
    "\n",
    "# Trigram dataframe\n",
    "trigram_pmi = pd.DataFrame(trigram_scores)\n",
    "trigram_pmi.columns = ['trigram', 'pmi']\n",
    "trigram_pmi.sort_values(by='pmi', axis = 0, ascending = False, inplace = True)\n",
    "print('Number of trigrams:',len(trigram_pmi.index))\n",
    "trigram_pmi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "055fd34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for trigrams with only noun-type structures\n",
    "def trigram_filter(trigram):\n",
    "    tag = pos(trigram)\n",
    "    if tag[0][1] not in ['JJ', 'NN'] and tag[1][1] not in ['JJ','NN']:\n",
    "        return False\n",
    "    if trigram[0] in stop_words or trigram[-1] in stop_words or trigram[1] in stop_words:\n",
    "        return False\n",
    "    if 'n' in trigram or 't' in trigram:\n",
    "         return False\n",
    "    if 'PRON' in trigram:\n",
    "        return False\n",
    "    return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fa4b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered trigrams: 136\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>pmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(buena, salud, guide)</td>\n",
       "      <td>25.723594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(phi, beta, kappa)</td>\n",
       "      <td>25.454133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(magna, cum, laude)</td>\n",
       "      <td>24.202595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(robert, wood, johnson)</td>\n",
       "      <td>21.496690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(graduated, magna, cum)</td>\n",
       "      <td>21.043672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   trigram        pmi\n",
       "0    (buena, salud, guide)  25.723594\n",
       "1       (phi, beta, kappa)  25.454133\n",
       "2      (magna, cum, laude)  24.202595\n",
       "3  (robert, wood, johnson)  21.496690\n",
       "4  (graduated, magna, cum)  21.043672"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_trigram = trigram_pmi[trigram_pmi.apply(lambda trigram: \\\n",
    "                                                 trigram_filter(trigram['trigram'])\\\n",
    "                                                 and trigram.pmi > 5, axis = 1)]\n",
    "\n",
    "print('Number of filtered trigrams:',len(filtered_trigram.index))\n",
    "filtered_trigram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0eb2bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buena salud guide',\n",
       " 'phi beta kappa',\n",
       " 'magna cum laude',\n",
       " 'robert wood johnson',\n",
       " 'graduated magna cum',\n",
       " 'doctor humane letter',\n",
       " 'current dollar term',\n",
       " 'wall street journal',\n",
       " 'boy girl club',\n",
       " 'carnegie mellon university']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining trigrams\n",
    "trigrams = [' '.join(x) for x in filtered_trigram.trigram.values if len(x[0]) > 2 or len(x[1]) > 2 and len(x[2]) > 2]\n",
    "trigrams[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f599c5",
   "metadata": {},
   "source": [
    "### Concatenate n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "801d1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate n-grams\n",
    "def replace_ngram(x):\n",
    "    for gram in trigrams:\n",
    "        x = x.replace(gram, '_'.join(gram.split()))\n",
    "    for gram in bigrams:\n",
    "        x = x.replace(gram, '_'.join(gram.split()))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa48d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all tokens into one string\n",
    "clean_articles = [' '.join(x) for x in all_tokens]\n",
    "\n",
    "# Remplace ngrams with underscore (_) versions\n",
    "ngram_articles = [replace_ngram(x) for x in clean_articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41fffe49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dr anabel jensen american educator author best known work curriculum utilizing emotional intelligence former director nueva learning center became president six second ceo synapse school currently professor notre dame de namur university anabel lee jensen born two u army officer danish descent began attending brigham young university graduated ba psychology master education received ph university_california_berkeley majored child development minored statistic executive director nueva learning center california helped develop self science curriculum featured daniel goleman book emotional intelligence matter iq helped bring eq mainstream former nueva school administrator teacher jensen karen mccown joshua freedman marsha rideout left school found six second eq network non_profit focused education eq founding president helped write training program psychometric assessment organization including six second emotional intelligence assessment sei youth version sei yv co_founded elementary middle school synapse school karen stone mccown full professor notre dame de namur university california teach psychology graduate student department chair school college education also principal advisor gifted support center advisor unite education jensen named one_top woman influence silicon_valley business_journal work field emotional intelligence interviewed frequently digital print publication quartz bizjournals com jensen authored article outlet priority magazine discovery channel including article greater part shared decision making nueva school roeper review second edition self science published jensen contributing published joy loss emotional life gifted child joshua freedman book emotional development emotional intelligence educational implication written based jensen providing curriculum access writer published feeling smart competency recommendation exercise keynote speaker national conference various topic crystal castle award exceptional service gifted community president national blue ribbon award excellence outstanding american american education nominated national teacher year program keller teaching excellence award notre dame university belmont california distinguished_service award california association gifted self science emotional intelligence curriculum isbn six second co_author handle care emotional intelligence activity book isbn six second joy loss emotional life gifted child co_author feeling smart isbn roeper review profile six secondsprofile notre dame synapse school'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbe23dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize reviews + remove stop words + remove names + remove words with less than 2 characters\n",
    "articles_w_ngrams = [word_tokenize(x) for x in ngram_articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26ebf3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jessica',\n",
       " 'mah',\n",
       " 'born',\n",
       " 'may',\n",
       " 'westchester',\n",
       " 'county',\n",
       " 'new_york',\n",
       " 'american',\n",
       " 'entrepreneur',\n",
       " 'mah',\n",
       " 'founded',\n",
       " 'several',\n",
       " 'company',\n",
       " 'including',\n",
       " 'indinero',\n",
       " 'mahway',\n",
       " 'mah',\n",
       " 'born',\n",
       " 'westchester',\n",
       " 'county',\n",
       " 'new_york',\n",
       " 'parent',\n",
       " 'entrepreneur',\n",
       " 'clothing',\n",
       " 'business',\n",
       " 'immigrant',\n",
       " 'hong_kong',\n",
       " 'relocated',\n",
       " 'united_state',\n",
       " 'mah',\n",
       " 'finished',\n",
       " 'high_school',\n",
       " 'age',\n",
       " 'joined',\n",
       " 'bard',\n",
       " 'college',\n",
       " 'simon',\n",
       " 'rock',\n",
       " 'age',\n",
       " 'mah',\n",
       " 'joined',\n",
       " 'university_california_berkeley',\n",
       " 'computer_science',\n",
       " 'program',\n",
       " 'graduated',\n",
       " 'age',\n",
       " 'mah',\n",
       " 'began',\n",
       " 'first',\n",
       " 'business',\n",
       " 'purchasing',\n",
       " 'server',\n",
       " 'space',\n",
       " 'bulk',\n",
       " 'selling',\n",
       " 'fraction',\n",
       " 'space',\n",
       " 'cheaper',\n",
       " 'price',\n",
       " 'age',\n",
       " 'started',\n",
       " 'first',\n",
       " 'internet',\n",
       " 'company',\n",
       " 'selling',\n",
       " 'computer',\n",
       " 'part',\n",
       " 'ebay',\n",
       " 'university_california_berkeley',\n",
       " 'mah',\n",
       " 'classmate',\n",
       " 'andy',\n",
       " 'su',\n",
       " 'co_founded',\n",
       " 'indinero',\n",
       " 'fintech',\n",
       " 'company',\n",
       " 'providing',\n",
       " 'accounting',\n",
       " 'financial',\n",
       " 'software',\n",
       " 'business',\n",
       " 'launched',\n",
       " 'firm',\n",
       " 'online',\n",
       " 'dashboard',\n",
       " 'month',\n",
       " 'graduating',\n",
       " 'computer_science',\n",
       " 'program',\n",
       " 'following',\n",
       " 'mah',\n",
       " 'graduation',\n",
       " 'su',\n",
       " 'applied',\n",
       " 'combinator',\n",
       " 'summer',\n",
       " 'program',\n",
       " 'presenting',\n",
       " 'idea',\n",
       " 'formally',\n",
       " 'investor',\n",
       " 'investor',\n",
       " 'signed',\n",
       " 'indinero',\n",
       " 'raised',\n",
       " 'million',\n",
       " 'angel',\n",
       " 'investor',\n",
       " 'raised',\n",
       " 'million',\n",
       " 'mah',\n",
       " 'received',\n",
       " 'recognition',\n",
       " 'named',\n",
       " 'forbes',\n",
       " 'enterprise',\n",
       " 'technology',\n",
       " 'category',\n",
       " 'inc',\n",
       " 'magazine_list',\n",
       " 'appeared',\n",
       " 'august',\n",
       " 'cover',\n",
       " 'inc',\n",
       " 'magazine',\n",
       " 'mah',\n",
       " 'founded',\n",
       " 'three',\n",
       " 'start',\n",
       " 'ups',\n",
       " 'including',\n",
       " 'internshipin',\n",
       " 'enterprise',\n",
       " 'software',\n",
       " 'service',\n",
       " 'saas',\n",
       " 'company',\n",
       " 'mahway',\n",
       " 'venture',\n",
       " 'builder',\n",
       " 'portfolio',\n",
       " 'five',\n",
       " 'company',\n",
       " 'attracted',\n",
       " 'capital',\n",
       " 'silicon_valley',\n",
       " 'investor',\n",
       " 'official',\n",
       " 'website']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_w_ngrams[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a3319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
